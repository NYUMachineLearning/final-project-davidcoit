{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numba\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import fftpack\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "import scipy.signal as sgn\n",
    "import scipy.misc\n",
    "from scipy.special import logsumexp as sp_logsumexp\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests as granger\n",
    "#from statsmodels.sandbox.distributions.mv_measures import mutual_info_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "def mutualinfo_kde(y, x, normed=True):\n",
    "    '''mutual information of two random variables estimated with kde\n",
    "    '''\n",
    "    nobs = len(x)\n",
    "    if not len(y) == nobs:\n",
    "        raise ValueError('both data arrays need to have the same size')\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    yx = np.vstack((y,x))\n",
    "    kde_x = gaussian_kde(x)(x)\n",
    "    kde_y = gaussian_kde(y)(y)\n",
    "    kde_yx = gaussian_kde(yx)(yx)\n",
    "\n",
    "    mi_obs = np.log(kde_yx) - np.log(kde_x) - np.log(kde_y)\n",
    "    mi = mi_obs.sum() / nobs\n",
    "    if normed:\n",
    "        mi_normed = np.sqrt(1. - np.exp(-2 * mi))\n",
    "        return mi_normed\n",
    "    else:\n",
    "        return mi\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "# import transfer entropy function from R:\n",
    "\n",
    "# calculate distance matrix from position matrix\n",
    "def distanceMatrix(plist):\n",
    "    n = np.shape(plist)[0]\n",
    "    dmat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dmat[i,j] = np.linalg.norm(POSITIONS[i]-POSITIONS[j])\n",
    "    return(dmat)\n",
    "\n",
    "# calculate undirected adjacency matrix\n",
    "def connectionMatrix(fmat, nlist):\n",
    "    n = np.shape(fmat)[1]\n",
    "    cmat = np.zeros((n,n))\n",
    "    for connection in nlist:\n",
    "        nfrom = connection[0] - 1\n",
    "        nto = connection[1] - 1\n",
    "        if connection[2] != 0:\n",
    "            cmat[nfrom, nto] = 1\n",
    "            cmat[nto, nfrom] = 1\n",
    "    return(cmat)\n",
    "\n",
    "# calculate directed adjacency matrix\n",
    "def projectionMatrix(fmat, nlist):\n",
    "    n = np.shape(fmat)[1]\n",
    "    pmat = np.zeros((n,n))\n",
    "    for connection in nlist:\n",
    "        nfrom = connection[0] - 1\n",
    "        nto = connection[1] - 1\n",
    "        ctype = connection[2]\n",
    "        pmat[nfrom, nto] = ctype\n",
    "    return(pmat)\n",
    "\n",
    "def spike_detect(flr, h=0.125, w=3):\n",
    "    s = np.zeros(np.shape(flr))\n",
    "    for j in range(np.shape(flr)[1]):\n",
    "        t = sgn.find_peaks(flr[:,j],\n",
    "                           h,\n",
    "                           width=w) \n",
    "        for i in t[0]:\n",
    "            s[i,j] = 1\n",
    "    return(s)\n",
    "\n",
    "def lp_1(track):    \n",
    "    # attempt hp on 2d matrix\n",
    "    try:\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = (track[i-1,j] + track[i,j] + track[i+1],j)     \n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]\n",
    "    \n",
    "    # if dimensional error, hp 1 dimensional\n",
    "    except:       \n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = (track[i-1] + track[i] + track[i+1])     \n",
    "            except:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def lp_2(track): \n",
    "    try:# attempt hp on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = (0.4* track[i-3,j] + 0.6*track[i-2,j] + 0.8*track[i-1,j] + track[i,j])     \n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]       \n",
    "    except:# if dimensional error, hp 1 dimensional\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = (0.4* track[i-3] + 0.6*track[i-2] + 0.8*track[i-1] + track[i])     \n",
    "            except:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def hp(track):\n",
    "    try:# attempt lp on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = track[i,j] - track[i-1,j]\n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]    \n",
    "    except:\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = track[i] - track[i-1]\n",
    "            except:\n",
    "                new_track[i] = track[i]         \n",
    "    return(new_track)\n",
    "\n",
    "def weight_filt(track):    \n",
    "    new_track = new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "    for i in range(np.shape(track)[0]):\n",
    "        for j in range(np.shape(track)[1]):\n",
    "            new_track[i,j] = (track[i,j] + 1) ** (1 + (1 / np.sum(track[i, :])))\n",
    "    return(new_track)\n",
    "    \n",
    "\n",
    "\n",
    "def thresh(track, th=0.05):\n",
    "    try:# attempt threshold on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                if track[i,j] < th:\n",
    "                    new_track[i,j] = 0\n",
    "                else:\n",
    "                    new_track[i,j] = track[i,j]\n",
    "    except:# threshold 1d track\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            if track[i] < th:\n",
    "                new_track[i] = 0\n",
    "            else:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def all_filter(track):\n",
    "    track = weight_filt((thresh(lp(hp_2(hp_1(track))))))\n",
    "    return(track)\n",
    "\n",
    "def pc(mat):\n",
    "    p = np.zeros((np.shape(mat)[1], np.shape(mat)[1]))\n",
    "    prec = linalg.inv(np.cov(mat, rowvar = False))\n",
    "    for i in range((np.shape(p)[0])):\n",
    "        for j in range((np.shape(p)[1])):\n",
    "            p[i, j] = -1 * prec[i,j] / (np.sqrt(prec[i,i]*prec[j,j]))\n",
    "    return(p)\n",
    "\n",
    "def mutual_info(matrix, window=50):\n",
    "    n = np.shape(matrix)[1]\n",
    "    MImat = np.zeros((n,n))\n",
    "    periods = []\n",
    "    for i in range(0, int(np.floor(np.shape(matrix)[0] / window)-1)):\n",
    "        periods.append([i*window, (i+1)*window])\n",
    "            \n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            MI = []\n",
    "            for p in periods:\n",
    "                #print(\"i={}, j={},p={}\".format(i,j,p))\n",
    "                if i!=j:\n",
    "                    info = mutual_info_classif(matrix[p[0]:p[1],i].reshape(-1,1), \n",
    "                                                  matrix[p[0]:p[1],j],\n",
    "                                                  n_neighbors=5, \n",
    "                                                  discrete_features=True)*1000\n",
    "                    MI.append(info)\n",
    "                else:\n",
    "                    MI.append(0)\n",
    "                \n",
    "                #print(\"{},{}: {}\".format(i,j,MI))\n",
    "            MImat[i,j] = (np.quantile(MI,.75))\n",
    "    return(MImat)\n",
    "\n",
    "\n",
    "def grangerMatrix(matrix, mem = 5):\n",
    "    # pass a spike train matrix\n",
    "    n = np.shape(matrix)[1]\n",
    "    gMat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i!=j:\n",
    "                f = []\n",
    "                c = matrix[:,(i,j)]\n",
    "                g = granger(c, maxlag = mem, verbose=False)\n",
    "                for k in g.keys():\n",
    "                    f.append(g[k][0]['ssr_ftest'][0])\n",
    "                gMat[i,j] = max(f)\n",
    "    return(gMat)\n",
    "\n",
    "\n",
    "\n",
    "def upper_thresh(matrix, th = 15):\n",
    "    for i in range(np.shape(matrix)[0]):\n",
    "        for j in range(np.shape(matrix)[1]):\n",
    "            if matrix[i,j]>th:\n",
    "                matrix[i,j]=th\n",
    "    return(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up file paths\n",
    "example = \"01\"\n",
    "\n",
    "# proj_dir = \"/gpfs/scratch/dmc421/ML/connect/\"\n",
    "# src_dir = \"{}src/\".format(proj_dir)\n",
    "# data_dir = \"{}data/\".format(proj_dir)\n",
    "# mat_dir = \"{}mat/\".format(proj_dir)\n",
    "\n",
    "# ffile = \"flr_{}.txt\".format(example)\n",
    "# nfile = \"net_{}.txt\".format(example)\n",
    "# pfile = \"pos_{}.txt\".format(example)\n",
    "\n",
    "# fpath = \"{}{}\".format(src_dir, ffile)\n",
    "# npath = \"{}{}\".format(src_dir, nfile)\n",
    "# ppath = \"{}{}\".format(src_dir, pfile)\n",
    "\n",
    "\n",
    "parent_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/\"\n",
    "source_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/src/\"\n",
    "data_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/data/\"\n",
    "\n",
    "\n",
    "ffile = \"fluorescence_iNet1_Size100_CC01inh.txt\"\n",
    "nfile = \"network_iNet1_Size100_CC01inh.txt\"\n",
    "pfile = 'networkPositions_iNet1_Size100_CC01inh.txt'\n",
    "\n",
    "fpath = \"{}{}\".format(source_path, ffile)\n",
    "npath = \"{}{}\".format(source_path, nfile)\n",
    "ppath = \"{}{}\".format(source_path, pfile)\n",
    "\n",
    "\n",
    "train_dir = \"{}{}\".format(data_path, \"train/\")\n",
    "validation_dir = \"{}{}\".format(data_path, \"validation/\")\n",
    "test_dir = \"{}{}\".format(data_path, \"test/\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Import data\n",
    "# Import data\n",
    "FLR = np.genfromtxt(fpath,\n",
    "                    delimiter=',')\n",
    "NETWORK = np.genfromtxt(npath,\n",
    "                        delimiter=',').astype(int)\n",
    "POSITIONS = np.genfromtxt(ppath,\n",
    "                          delimiter=',')\n",
    "\n",
    "CONNECTIONS = connectionMatrix(FLR, NETWORK)\n",
    "\n",
    "PROJECTIONS = projectionMatrix(FLR, NETWORK)\n",
    "\n",
    "DISTANCES = distanceMatrix(POSITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process FLR data to weight-adjusted\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# freq filters\n",
    "FFLR = hp(lp_2(lp_1(FLR)))\n",
    "#[0,1] normalization\n",
    "scale = scaler.fit(FFLR)\n",
    "FFLR = scale.transform(FFLR)\n",
    "# weight and thresholding\n",
    "WFLR = weight_filt(FFLR)\n",
    "WFLR = upper_thresh(WFLR)\n",
    "# spike detection\n",
    "SPK_FLR=spike_detect(WFLR, h = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Granger causality matrix and save to file\n",
    "G = grangerMatrix(SPK_FLR[:,:])\n",
    "np.savetxt(\"{}granger_{}.csv\".format(mat_dir, example), G, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mutualinfo_kde(WFLR[0:100,0], WFLR[0:100,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((100,100))\n",
    "b = np.zeros((100,100))\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        if i!=j:\n",
    "            a[i,j] = mutualinfo_kde(FFLR[0:1000,i], FFLR[0:1000,j])\n",
    "            b[i,j] = mutualinfo_kde(WFLR[0:1000,i], WFLR[0:1000,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c6901587fe0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutualinfo_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# d = mutualinfo_kde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-524677f12050>\u001b[0m in \u001b[0;36mmutualinfo_kde\u001b[0;34m(y, x, normed)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0myx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mkde_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mkde_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mkde_yx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/connectomics/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscaled_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = mutualinfo_kde(FLR[:,1], FLR[:,2])\n",
    "# d = mutualinfo_kde\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6b4612946461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrelate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/connectomics/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mcorrelate\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \"\"\"\n\u001b[1;32m    711\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
