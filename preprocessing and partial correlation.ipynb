{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numba\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import fftpack\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "import scipy.signal as sgn\n",
    "import scipy.misc\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.vectors import IntVector, FloatVector\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "# import transfer entropy function from R:\n",
    "TXE = rpackages.importr(\"RTransferEntropy\")\n",
    "def TE_matrix(matrix, memory=20):\n",
    "    n = np.shape(matrix)[1]\n",
    "    TE = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                TE[i,j] = TXE.transfer_entropy(IntVector(matrix[:,i]), IntVector(matrix[:,j]), \n",
    "                                               lx = memory, ly = memory,  \n",
    "                                               entropy = \"Shannon\", \n",
    "                                               q = 1,\n",
    "                                              quiet=True)[2][0]\n",
    "    return(TE)\n",
    "\n",
    "\n",
    "# calculate distance matrix from position matrix\n",
    "def distanceMatrix(plist):\n",
    "    n = np.shape(plist)[0]\n",
    "    dmat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dmat[i,j] = np.linalg.norm(POSITIONS[i]-POSITIONS[j])\n",
    "    return(dmat)\n",
    "\n",
    "# calculate undirected adjacency matrix\n",
    "def connectionMatrix(fmat, nlist):\n",
    "    n = np.shape(fmat)[1]\n",
    "    cmat = np.zeros((n,n))\n",
    "    for connection in nlist:\n",
    "        nfrom = connection[0] - 1\n",
    "        nto = connection[1] - 1\n",
    "        if connection[2] != 0:\n",
    "            cmat[nfrom, nto] = 1\n",
    "            cmat[nto, nfrom] = 1\n",
    "    return(cmat)\n",
    "\n",
    "# calculate directed adjacency matrix\n",
    "def projectionMatrix(fmat, nlist):\n",
    "    n = np.shape(fmat)[1]\n",
    "    pmat = np.zeros((n,n))\n",
    "    for connection in nlist:\n",
    "        nfrom = connection[0] - 1\n",
    "        nto = connection[1] - 1\n",
    "        ctype = connection[2]\n",
    "        cmat[nfrom, nto] = ctype\n",
    "    return(pmat)\n",
    "\n",
    "def spike_detect(flr, h=0.125, w=10):\n",
    "    s = np.zeros(np.shape(flr))\n",
    "    for j in range(np.shape(flr)[1]):\n",
    "        t = sgn.find_peaks(flr[:,j],\n",
    "                           h,\n",
    "                           width=w) \n",
    "        for i in t[0]:\n",
    "            s[i,j] = 1\n",
    "    return(s)\n",
    "\n",
    "def hp_1(track):\n",
    "    \n",
    "    # attempt hp on 2d matrix\n",
    "    try:\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = (track[i-1,j] + track[i,j] + track[i+1],j)     \n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]\n",
    "    \n",
    "    # if dimensional error, hp 1 dimensional\n",
    "    except:       \n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = (track[i-1] + track[i] + track[i+1])     \n",
    "            except:\n",
    "                new_track[i] = track[i]\n",
    "\n",
    "    return(new_track)\n",
    "\n",
    "def hp_2(track): \n",
    "    try:# attempt hp on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = (0.4* track[i-3,j] + 0.6*track[i-2,j] + 0.8*track[i-1,j] + track[i,j])     \n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]       \n",
    "    except:# if dimensional error, hp 1 dimensional\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = (0.4* track[i-3] + 0.6*track[i-2] + 0.8*track[i-1] + track[i])     \n",
    "            except:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def lp(track):\n",
    "    try:# attempt lp on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                try:\n",
    "                    new_track[i,j] = track[i,j] - track[i-1,j]\n",
    "                except:\n",
    "                    new_track[i,j] = track[i,j]    \n",
    "    except:\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            try:\n",
    "                new_track[i] = track[i] - track[i-1]\n",
    "            except:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def thresh(track, th=0.05):\n",
    "    try:# attempt threshold on 2d matrix\n",
    "        new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "        for i in range(np.shape(track)[0]):\n",
    "            for j in range(np.shape(track)[1]):\n",
    "                if track[i,j] < th:\n",
    "                    new_track[i,j] = 0\n",
    "                else:\n",
    "                    new_track[i,j] = track[i,j]\n",
    "    except:# threshold 1d track\n",
    "        new_track = np.zeros(len(track))\n",
    "        for i in range(len(track)):\n",
    "            if track[i] < th:\n",
    "                new_track[i] = 0\n",
    "            else:\n",
    "                new_track[i] = track[i]\n",
    "    return(new_track)\n",
    "\n",
    "def all_filter(track):\n",
    "    track = thresh(lp(hp_2(hp_1(track))))\n",
    "    return(track)\n",
    "\n",
    "def pc(mat):\n",
    "    p = np.zeros((np.shape(mat)[1], np.shape(mat)[1]))\n",
    "    prec = linalg.inv(np.cov(mat, rowvar = False))\n",
    "    print(linalg.det(prec))\n",
    "    for i in range((np.shape(p)[0])):\n",
    "        for j in range((np.shape(p)[1])):\n",
    "            p[i, j] = -1 * prec[i,j] / (np.sqrt(prec[i,i]*prec[j,j]))\n",
    "    return(p)\n",
    "\n",
    "def mutual_info(matrix, window=50):\n",
    "    n = np.shape(matrix)[1]\n",
    "    MImat = np.zeros((n,n))\n",
    "    periods = []\n",
    "    for i in range(0, int(np.floor(np.shape(matrix)[0] / window)-1)):\n",
    "        periods.append([i*window, (i+1)*window])\n",
    "            \n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            MI = []\n",
    "            for p in periods:\n",
    "                #print(\"i={}, j={},p={}\".format(i,j,p))\n",
    "                if i!=j:\n",
    "                    info = mutual_info_classif(matrix[p[0]:p[1],i].reshape(-1,1), \n",
    "                                                  matrix[p[0]:p[1],j],\n",
    "                                                  n_neighbors=5,\n",
    "                                                  discrete_features=True)\n",
    "                    MI.append(info)\n",
    "                else:\n",
    "                    MI.append(0)\n",
    "                \n",
    "                #print(\"{},{}: {}\".format(i,j,MI))\n",
    "            MImat[i,j] = (np.mean(MI))\n",
    "    return(MImat)\n",
    "\n",
    "def weight_filt(track):    \n",
    "    new_track = np.zeros((np.shape(track)[0], np.shape(track)[1]))\n",
    "    for i in range(np.shape(track)[0]):\n",
    "        for j in range(np.shape(track)[1]):\n",
    "            s = np.sum(track[i,:])\n",
    "            if abs(s) < 0.01:\n",
    "                new_track[i,j] = 1\n",
    "            else:\n",
    "                new_track[i,j] = (track[i,j] + 1) ** (1 + (1 / np.sum(track[i, :])))\n",
    "    return(new_track)\n",
    "\n",
    "def pc(mat):\n",
    "    p = np.zeros((np.shape(mat)[1], np.shape(mat)[1]))\n",
    "    prec = linalg.inv(np.cov(mat, rowvar = False))\n",
    "    for i in range((np.shape(p)[0])):\n",
    "        for j in range((np.shape(p)[1])):\n",
    "            p[i, j] = -1 * prec[i,j] / (np.sqrt(prec[i,i]*prec[j,j]))\n",
    "    return(p)\n",
    "\n",
    "def mutual_info(matrix, window=50):\n",
    "    n = np.shape(matrix)[1]\n",
    "    MImat = np.zeros((n,n))\n",
    "    periods = []\n",
    "    for i in range(0, int(np.floor(np.shape(matrix)[0] / window)-1)):\n",
    "        periods.append([i*window, (i+1)*window])\n",
    "            \n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            MI = []\n",
    "            for p in periods:\n",
    "                #print(\"i={}, j={},p={}\".format(i,j,p))\n",
    "                if i!=j:\n",
    "                    info = mutual_info_classif(matrix[p[0]:p[1],i].reshape(-1,1), \n",
    "                                                  matrix[p[0]:p[1],j],\n",
    "                                                  n_neighbors=5, \n",
    "                                                  discrete_features=True)*1000\n",
    "                    MI.append(info)\n",
    "                else:\n",
    "                    MI.append(0)\n",
    "                \n",
    "                #print(\"{},{}: {}\".format(i,j,MI))\n",
    "            MImat[i,j] = (np.quantile(MI,.75))\n",
    "    return(MImat)\n",
    "\n",
    "def grangerMatrix(matrix, mem = 5):\n",
    "    # pass a spike train matrix\n",
    "    n = np.shape(matrix)[1]\n",
    "    gMat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i!=j:\n",
    "                f = []\n",
    "                c = matrix[:,(i,j)]\n",
    "                g = granger(c, maxlag = mem, verbose=False)\n",
    "                for k in g.keys():\n",
    "                    f.append(g[k][0]['ssr_ftest'][0])\n",
    "                gMat[i,j] = max(f)\n",
    "    return(gMat)\n",
    "\n",
    "\n",
    "\n",
    "def upper_thresh(matrix, th = 15):\n",
    "    for i in range(np.shape(matrix)[0]):\n",
    "        for j in range(np.shape(matrix)[1]):\n",
    "            if matrix[i,j]>th:\n",
    "                matrix[i,j]=th\n",
    "    return(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "parent_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/\"\n",
    "source_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/src/\"\n",
    "data_path = \"/Users/David/Documents/NYU/MACHINE_LEARNING/netconnect/data/\"\n",
    "\n",
    "\n",
    "ffile = \"fluorescence_iNet1_Size100_CC06inh.txt\"\n",
    "nfile = \"network_iNet1_Size100_CC06inh.txt\"\n",
    "pfile = 'networkPositions_iNet1_Size100_CC06inh.txt'\n",
    "\n",
    "fpath = \"{}{}\".format(source_path, ffile)\n",
    "npath = \"{}{}\".format(source_path, nfile)\n",
    "ppath = \"{}{}\".format(source_path, pfile)\n",
    "\n",
    "\n",
    "train_dir = \"{}{}\".format(data_path, \"train/\")\n",
    "validation_dir = \"{}{}\".format(data_path, \"validation/\")\n",
    "test_dir = \"{}{}\".format(data_path, \"test/\")\n",
    "\n",
    "# Import data\n",
    "FLR = np.genfromtxt(fpath,\n",
    "                    delimiter=',')\n",
    "NETWORK = np.genfromtxt(npath,\n",
    "                        delimiter=',').astype(int)\n",
    "POSITIONS = np.genfromtxt(ppath,\n",
    "                          delimiter=',')\n",
    "\n",
    "# high pass and low pass filters, scale to 0:1\n",
    "fflr = lp(hp_2(hp_1(FLR)))\n",
    "scaler = MinMaxScaler()\n",
    "scale = scaler.fit(fflr)\n",
    "sflr = scale.transform(fflr)\n",
    "# weight by network activity\n",
    "wflr = weight_filt(sflr)\n",
    "# center weighted flr on mean\n",
    "cflr = wflr - np.mean(wflr)\n",
    "# threshold and spike detect\n",
    "tflr = thresh(cflr, th=0.15)\n",
    "spkflr = spike_detect(tflr, w = 0.1, h = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "tempout = \"/Users/David/Desktop/output/\"\n",
    "# discrete and continuous partial correlation\n",
    "discrete = pc(spkflr)\n",
    "continuous = pc(cflr)\n",
    "\n",
    "# save spikes\n",
    "np.savetxt(\"{}SPIKES_06.csv\".format(tempout), spkflr, delimiter = \",\")\n",
    "# save discrete pc\n",
    "np.savetxt(\"{}PC_DISC_06.csv\".format(tempout), discrete, delimiter = \",\")\n",
    "# save continuous pc\n",
    "np.savetxt(\"{}PC_CONT_06.csv\".format(tempout), continuous, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
